//example of some shaders compiled
flat basic.vs flat.fs
texture basic.vs texture.fs
light basic.vs light.fs
depth quad.vs depth.fs
multi basic.vs multi.fs
single basic.vs light_single_pass.fs
gbuffers basic.vs gbuffers.fs
deferred quad.vs deferred.fs
deferred_ws basic.vs deferred_PBR.fs
deferred_PBR quad.vs deferred_PBR.fs
ambient quad.vs ambient.fs
ssao quad.vs ssao.fs
gamma quad.vs gamma.fs
probe basic.vs probe.fs
irradiance quad.vs irradiance.fs
skybox basic.vs skybox.fs
reflection_probe basic.vs reflection_probe.fs
volumetric quad.vs volumetric.fs

\basic.vs

#version 330 core

in vec3 a_vertex;
in vec3 a_normal;
in vec2 a_coord;
in vec4 a_color;

uniform vec3 u_camera_pos;

uniform mat4 u_model;
uniform mat4 u_viewprojection;

//this will store the color for the pixel shader
out vec3 v_position;
out vec3 v_world_position;
out vec3 v_normal;
out vec2 v_uv;
out vec4 v_color;

uniform float u_time;

void main()
{	
	//calcule the normal in camera space (the NormalMatrix is like ViewMatrix but without traslation)
	v_normal = (u_model * vec4( a_normal, 0.0) ).xyz;
	
	//calcule the vertex in object space
	v_position = a_vertex;
	v_world_position = (u_model * vec4( v_position, 1.0) ).xyz;
	
	//store the color in the varying var to use it from the pixel shader
	v_color = a_color;

	//store the texture coordinates
	v_uv = a_coord;

	//calcule the position of the vertex using the matrices
	gl_Position = u_viewprojection * vec4( v_world_position, 1.0 );
}

\quad.vs

#version 330 core

in vec3 a_vertex;
in vec2 a_coord;
out vec2 v_uv;

void main()
{	
	v_uv = a_coord;
	gl_Position = vec4( a_vertex, 1.0 );
}


\flat.fs

#version 330 core

uniform vec4 u_color;

out vec4 FragColor;

void main()
{
	FragColor = u_color;
}


\texture.fs

#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;
in vec4 v_color;

uniform vec4 u_color;
uniform sampler2D u_texture;
uniform float u_time;
uniform float u_alpha_cutoff;

out vec4 FragColor;

void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;
	color *= texture( u_texture, v_uv );

	if(color.a < u_alpha_cutoff)
		discard;

	FragColor = color;
}

\multi.fs

#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;

uniform vec4 u_color;
uniform sampler2D u_texture;
uniform float u_time;
uniform float u_alpha_cutoff;

layout(location = 0) out vec4 FragColor;
layout(location = 1) out vec4 NormalColor;

void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;
	color *= texture( u_texture, uv );

	if(color.a < u_alpha_cutoff)
		discard;

	vec3 N = normalize(v_normal);

	FragColor = color;
	NormalColor = vec4(N,1.0);
}


\depth.fs

#version 330 core

uniform vec2 u_camera_nearfar;
uniform sampler2D u_texture; //depth map
in vec2 v_uv;
out vec4 FragColor;

void main()
{
	float n = u_camera_nearfar.x;
	float f = u_camera_nearfar.y;
	float z = texture2D(u_texture,v_uv).x;
	if( n == 0.0 && f == 1.0 )
		FragColor = vec4(z);
	else
		FragColor = vec4( n * (z + 1.0) / (f + n - z * (f - n)) );
}


\instanced.vs

#version 330 core

in vec3 a_vertex;
in vec3 a_normal;
in vec2 a_coord;

in mat4 u_model;

uniform vec3 u_camera_pos;

uniform mat4 u_viewprojection;

//this will store the color for the pixel shader
out vec3 v_position;
out vec3 v_world_position;
out vec3 v_normal;
out vec2 v_uv;

void main()
{	
	//calcule the normal in camera space (the NormalMatrix is like ViewMatrix but without traslation)
	v_normal = (u_model * vec4( a_normal, 0.0) ).xyz;
	
	//calcule the vertex in object space
	v_position = a_vertex;
	v_world_position = (u_model * vec4( a_vertex, 1.0) ).xyz;
	
	//store the texture coordinates
	v_uv = a_coord;

	//calcule the position of the vertex using the matrices
	gl_Position = u_viewprojection * vec4( v_world_position, 1.0 );
}


\light_single_pass.fs

#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;
in vec4 v_color;

uniform vec4 u_color;
uniform sampler2D u_texture;
uniform float u_time;
uniform float u_alpha_cutoff;

const int max_lights = 5;

uniform vec3 u_ambient_light;

uniform int num_lights;

uniform int u_lights_type[max_lights];
uniform vec3 u_lights_color[max_lights];
uniform vec3 u_lights_position[max_lights];
uniform float u_lights_max_distance[max_lights];

uniform vec3 u_lights_direction[max_lights];
uniform float u_lights_cone_angle[max_lights];
uniform float u_lights_exp[max_lights];

uniform int u_light_casts_shadows;
uniform sampler2D u_light_shadowmap;
uniform mat4 u_shadow_viewproj;
uniform float u_shadow_bias;

out vec4 FragColor;

float testShadowmap(vec3 pos)
{
    //project our 3D position to the shadowmap
    vec4 proj_pos = u_shadow_viewproj * vec4(pos,1.0);

    //from homogeneus space to clip space
    vec2 shadow_uv = proj_pos.xy / proj_pos.w;

    //from clip space to uv space
    shadow_uv = shadow_uv * 0.5 + vec2(0.5);

    //get point depth [-1 .. +1] in non-linear space
    float real_depth = (proj_pos.z - u_shadow_bias) / proj_pos.w;

    //normalize from [-1..+1] to [0..+1] still non-linear
    real_depth = real_depth * 0.5 + 0.5;

    //read depth from depth buffer in [0..+1] non-linear
    float shadow_depth = texture( u_light_shadowmap, shadow_uv).x;

    //compute final shadow factor by comparing
    float shadow_factor = 1.0;

    //we can compare them, even if they are not linear
    if( shadow_depth < real_depth )
        shadow_factor = 0.0;

    return shadow_factor;
}

void main()
{
	vec3 N = normalize(v_normal);
	vec2 uv = v_uv;
	vec4 color = u_color;
	color *= texture( u_texture, v_uv );

	if(color.a < u_alpha_cutoff)
		discard;

    vec3 total_light = vec3(u_ambient_light);

   for(int i = 0; i<num_lights; i++){

           vec3 L = u_lights_position[i] - v_world_position;
           float distance = length(L);
           L /= distance;

           float attenuation_factor = u_lights_max_distance[i] - distance;
           attenuation_factor /= u_lights_max_distance[i];
           attenuation_factor = max(attenuation_factor, 0.0);

           float NdotL = clamp(dot(N,L), 0.0, 1.0);

           float spot_factor = 1.0;

           if(u_lights_type[i] == 1){
               float spot_cosine = dot(L, u_lights_direction[i]);
               if(spot_cosine >= u_lights_cone_angle[i])
               {
                   spot_factor = pow(spot_cosine, u_lights_exp[i]);
               }
               else{
                   spot_factor = 0.0;
               }
           }

           spot_factor = clamp(spot_factor, 0.0, 1.0);

           total_light += attenuation_factor * NdotL * u_lights_color[i] * spot_factor;
       }




	color.xyz *= total_light;


	FragColor = color;
}


\light.fs

#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;
in vec4 v_color;

uniform vec4 u_color;
uniform vec3 u_emissive;
uniform sampler2D u_texture;
uniform sampler2D u_emissive_texture;
uniform float u_time;
uniform float u_alpha_cutoff;

uniform vec3 u_ambient_light;

uniform int u_light_type;
uniform vec3 u_light_color;
uniform vec3 u_light_position;
uniform float u_light_max_distance;
uniform vec3 u_light_direction;
uniform float u_light_cone_angle;
uniform float u_light_exp;

uniform int u_light_casts_shadows;
uniform sampler2D u_light_shadowmap;
uniform mat4 u_shadow_viewproj;
uniform float u_shadow_bias;

out vec4 FragColor;

float testShadowmap(vec3 pos)
{
    //project our 3D position to the shadowmap
    vec4 proj_pos = u_shadow_viewproj * vec4(pos,1.0);

    //from homogeneus space to clip space
    vec2 shadow_uv = proj_pos.xy / proj_pos.w;

    //from clip space to uv space
    shadow_uv = shadow_uv * 0.5 + vec2(0.5);

    //get point depth [-1 .. +1] in non-linear space
    float real_depth = (proj_pos.z - u_shadow_bias) / proj_pos.w;

    //normalize from [-1..+1] to [0..+1] still non-linear
    real_depth = real_depth * 0.5 + 0.5;

    //read depth from depth buffer in [0..+1] non-linear
    float shadow_depth = texture( u_light_shadowmap, shadow_uv).x;

    //compute final shadow factor by comparing
    float shadow_factor = 1.0;

    //we can compare them, even if they are not linear
    if( shadow_depth < real_depth )
        shadow_factor = 0.0;

    return shadow_factor;
}

void main()
{
	vec3 N = normalize(v_normal);
	vec2 uv = v_uv;
	vec4 color = u_color;
	color *= texture( u_texture, v_uv );

	if(color.a < u_alpha_cutoff)
		discard;
    

    vec3 L;
    
    if(u_light_type == 2)
    {
        L = u_light_direction;
    }
    else
    {
        L = u_light_position - v_world_position;
    }
    
	// vec3 L = u_light_position - v_world_position;
	
	float distance = length(L);
	L /= distance;


	float attenuation_factor = u_light_max_distance - distance;
	attenuation_factor /= u_light_max_distance;
	attenuation_factor = max(attenuation_factor, 0.0);

	float NdotL = clamp(dot(N,L), 0.0, 1.0);

    
    float spot_factor = 1.0;
    if(u_light_type == 1){
        float spot_cosine = dot(L, u_light_direction);
        if(spot_cosine >= u_light_cone_angle){
            spot_factor = pow(spot_cosine, u_light_exp);
        }
        else{
            spot_factor = 0.0;
        }
    }
    spot_factor = clamp(spot_factor, 0, 1);

    
    float shadow_factor = 1.0;
    if(u_light_casts_shadows == 1){
        shadow_factor = testShadowmap(v_world_position);
    }

    
    vec3 total_light = vec3(u_ambient_light);
	total_light += NdotL * u_light_color * attenuation_factor * spot_factor * shadow_factor;
	total_light += texture(u_emissive_texture, v_uv).xyz * u_emissive;

	
	color.xyz *= total_light;
	FragColor = color;
}


\gbuffers.fs

#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;
in vec4 v_color;

uniform vec4 u_color;
uniform vec3 u_emissive;
uniform sampler2D u_texture;
uniform sampler2D u_emissive_texture;
uniform sampler2D u_metallic_roughness_texture;
uniform float u_time;
uniform float u_alpha_cutoff;

layout(location = 0) out vec4 gb0;
layout(location = 1) out vec4 gb1;
layout(location = 2) out vec4 gb2;
layout(location = 3) out vec4 gb3;

void main()
{
	vec3 N = normalize(v_normal);
	
	vec2 uv = v_uv;
	vec4 color = u_color;
	color *= texture( u_texture, v_uv );

	if(color.a < u_alpha_cutoff)
		discard;
		
	vec3 occlussion_metallic_roughness = texture(u_metallic_roughness_texture, uv).xyz;
	float roughness = texture(u_metallic_roughness_texture, uv).z;
	
    vec3 emissive = texture(u_emissive_texture, uv).xyz * u_emissive;

	gb0 = vec4(color.xyz, 1.0);
	gb1 = vec4(N * 0.5 + vec3(0.5), 1.0);
	gb2 = vec4(occlussion_metallic_roughness, 1.0);
	gb3 = vec4(emissive, 1.0);
}


\deferred.fs

#version 330 core

in vec2 v_uv;

uniform float u_time;
uniform float u_alpha_cutoff;

uniform sampler2D u_gb0_texture;
uniform sampler2D u_gb1_texture;
uniform sampler2D u_gb2_texture;
uniform sampler2D u_depth_texture;

uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;

uniform vec3 u_ambient_light;

uniform int u_light_type;
uniform vec3 u_light_color;
uniform vec3 u_light_position;
uniform float u_light_max_distance;
uniform vec3 u_light_direction;
uniform float u_light_cone_angle;
uniform float u_light_exp;

uniform int u_light_casts_shadows;
uniform sampler2D u_light_shadowmap;
uniform mat4 u_shadow_viewproj;
uniform float u_shadow_bias;

out vec4 FragColor;

float testShadowmap(vec3 pos)
{
    //project our 3D position to the shadowmap
    vec4 proj_pos = u_shadow_viewproj * vec4(pos,1.0);

    //from homogeneus space to clip space
    vec2 shadow_uv = proj_pos.xy / proj_pos.w;

    //from clip space to uv space
    shadow_uv = shadow_uv * 0.5 + vec2(0.5);

    //get point depth [-1 .. +1] in non-linear space
    float real_depth = (proj_pos.z - u_shadow_bias) / proj_pos.w;

    //normalize from [-1..+1] to [0..+1] still non-linear
    real_depth = real_depth * 0.5 + 0.5;

    //read depth from depth buffer in [0..+1] non-linear
    float shadow_depth = texture( u_light_shadowmap, shadow_uv).x;

    //compute final shadow factor by comparing
    float shadow_factor = 1.0;

    //we can compare them, even if they are not linear
    if( shadow_depth < real_depth )
        shadow_factor = 0.0;

    return shadow_factor;
}

void main()
{

    vec2 uv = gl_FragCoord.xy * u_iRes.xy;
    
    vec4 gb0_color = texture(u_gb0_texture, uv);
	vec4 color = vec4(gb0_color.xyz, 1.0);
	
	vec4 gb1_color = texture(u_gb1_texture, uv);
	vec3 N = normalize(gb1_color.xyz * 2.0 - vec3(1.0));
	
	float depth = texture(u_depth_texture, uv).x;
	
	vec4 screen_pos = vec4(uv.x*2.0-1.0, uv.y*2.0-1.0, depth*2.0-1.0, 1.0);
    vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 world_position = proj_worldpos.xyz / proj_worldpos.w;

    vec3 L;
    
    if(u_light_type == 2)
    {
        L = u_light_direction;
    }
    else
    {
        L = u_light_position - world_position;
    }
    
    // vec3 L = u_light_position - world_position;
    
    float distance = length(L);
    L /= distance;


    float attenuation_factor = u_light_max_distance - distance;
    attenuation_factor /= u_light_max_distance;
    attenuation_factor = max(attenuation_factor, 0.0);

    float NdotL = clamp(dot(N,L), 0.0, 1.0);

    
    float spot_factor = 1.0;
    if(u_light_type == 1){
        float spot_cosine = dot(L, u_light_direction);
        if(spot_cosine >= u_light_cone_angle){
            spot_factor = pow(spot_cosine, u_light_exp);
        }
        else{
            spot_factor = 0.0;
        }
    }
    spot_factor = clamp(spot_factor, 0, 1);

    
    float shadow_factor = 1.0;
    if(u_light_casts_shadows == 1){
        shadow_factor = testShadowmap(world_position);
    }

    
    vec3 total_light = vec3(u_ambient_light);
    total_light += NdotL * u_light_color * attenuation_factor * spot_factor * shadow_factor;
    //total_light += texture(u_emissive_texture, v_uv).xyz * u_emissive;

    
    color.xyz *= total_light;
    FragColor = color;
}


\deferred_PBR.fs

#version 330 core

in vec2 v_uv;

uniform vec3 u_camera_position;

uniform float u_time;
uniform float u_alpha_cutoff;

uniform sampler2D u_gb0_texture;
uniform sampler2D u_gb1_texture;
uniform sampler2D u_gb2_texture;
uniform sampler2D u_gb3_texture;
uniform sampler2D u_depth_texture;
uniform sampler2D u_ssao_texture;

uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;

uniform int u_light_type;
uniform vec3 u_light_color;
uniform vec3 u_light_position;
uniform float u_light_max_distance;
uniform vec3 u_light_direction;
uniform float u_light_cone_angle;
uniform float u_light_exp;

uniform int u_light_casts_shadows;
uniform sampler2D u_light_shadowmap;
uniform mat4 u_shadow_viewproj;
uniform float u_shadow_bias;

out vec4 FragColor;

float testShadowmap(vec3 pos)
{
    //project our 3D position to the shadowmap
    vec4 proj_pos = u_shadow_viewproj * vec4(pos,1.0);

    //from homogeneus space to clip space
    vec2 shadow_uv = proj_pos.xy / proj_pos.w;

    //from clip space to uv space
    shadow_uv = shadow_uv * 0.5 + vec2(0.5);

    //get point depth [-1 .. +1] in non-linear space
    float real_depth = (proj_pos.z - u_shadow_bias) / proj_pos.w;

    //normalize from [-1..+1] to [0..+1] still non-linear
    real_depth = real_depth * 0.5 + 0.5;

    //read depth from depth buffer in [0..+1] non-linear
    float shadow_depth = texture( u_light_shadowmap, shadow_uv).x;

    //compute final shadow factor by comparing
    float shadow_factor = 1.0;

    //we can compare them, even if they are not linear
    if( shadow_depth < real_depth )
        shadow_factor = 0.0;

    return shadow_factor;
}

// Fresnel term with scalar optimization(f90=1)
float F_Schlick( const in float VoH, 
const in float f0)
{
	float f = pow(1.0 - VoH, 5.0);
	return f0 + (1.0 - f0) * f;
}

float F_Schlick( const in float VoH, const in float f0, float f90)
{
    float f = pow(1.0 - VoH, 5.0);
	return f0 + (f90 - f0) * f;
}



// Fresnel term with colorized fresnel
vec3 F_Schlick( const in float VoH, 
const in vec3 f0)
{
	float f = pow(1.0 - VoH, 5.0);
	return f0 + (vec3(1.0) - f0) * f;
}

#define RECIPROCAL_PI 0.3183098861837697

// Diffuse Reflections: Disney BRDF using retro-reflections using F term, this is much more complex!!
float Fd_Burley ( const in float NoV, const in float NoL,
const in float LoH, 
const in float linearRoughness)
{
        float f90 = 0.5 + 2.0 * linearRoughness * LoH * LoH;
        float lightScatter = F_Schlick(NoL, 1.0, f90);
        float viewScatter  = F_Schlick(NoV, 1.0, f90);
        return lightScatter * viewScatter * RECIPROCAL_PI;
}



// Geometry Term: Geometry masking/shadowing due to microfacets
float GGX(float NdotV, float k){
	return NdotV / (NdotV * (1.0 - k) + k);
}
	
float G_Smith( float NdotV, float NdotL, float roughness)
{
	float k = pow(roughness + 1.0, 2.0) / 8.0;
	return GGX(NdotL, k) * GGX(NdotV, k);
}


// Normal Distribution Function using GGX Distribution
float D_GGX (	const in float NoH, 
const in float linearRoughness )
{
	float a2 = linearRoughness * linearRoughness;
	float f = (NoH * NoH) * (a2 - 1.0) + 1.0;
	return a2 / (3.141516 * f * f);
}


//this is the cook torrance specular reflection model
vec3 specularBRDF( float roughness, vec3 f0, 
float NoH, float NoV, float NoL, float LoH )
{
float a = roughness * roughness;

// Normal Distribution Function
float D = D_GGX( NoH, a );

	// Fresnel Function
	vec3 F = F_Schlick( LoH, f0 );

	// Visibility Function (shadowing/masking)
	float G = G_Smith( NoV, NoL, roughness );
		
	// Norm factor
	vec3 spec = D * G * F;
	spec /= (4.0 * NoL * NoV + 1e-6);

	return spec;
}


void main()
{

    vec2 uv = gl_FragCoord.xy * u_iRes.xy;
    
    vec4 gb0_color = texture(u_gb0_texture, uv);
	vec4 color = vec4(gb0_color.xyz, 1.0);
	color = vec4(pow(color.xyz,vec3(2.2)),1.0);
	
	vec4 gb1_color = texture(u_gb1_texture, uv);
	vec3 N = normalize(gb1_color.xyz * 2.0 - vec3(1.0));
	
	vec4 gb2_color = texture(u_gb2_texture, uv);
	vec3 occlusion_metallic_roughness = gb2_color.xyz;
	
	vec4 gb3_color = texture(u_gb3_texture, uv);
	vec4 emissive = vec4(pow(gb3_color.xyz, vec3(2.2)),1.0);
	
	float depth = texture(u_depth_texture, uv).x;
	
	vec4 screen_pos = vec4(uv.x*2.0-1.0, uv.y*2.0-1.0, depth*2.0-1.0, 1.0);
    vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 world_position = proj_worldpos.xyz / proj_worldpos.w;

    vec3 L;
    
    if(u_light_type == 2)
    {
        L = u_light_direction;
    }
    else
    {
        L = u_light_position - world_position;
    }
    
    // vec3 L = u_light_position - world_position;
    
    float distance = length(L);
    L /= distance;


    float attenuation_factor = u_light_max_distance - distance;
    attenuation_factor /= u_light_max_distance;
    attenuation_factor = max(attenuation_factor, 0.0);

    float NdotL = clamp(dot(N,L), 0.0, 1.0);

    
    float spot_factor = 1.0;
    if(u_light_type == 1){
        float spot_cosine = dot(L, u_light_direction);
        if(spot_cosine >= u_light_cone_angle){
            spot_factor = pow(spot_cosine, u_light_exp);
        }
        else{
            spot_factor = 0.0;
        }
    }
    spot_factor = clamp(spot_factor, 0, 1);

    
    float shadow_factor = 1.0;
    if(u_light_casts_shadows == 1){
        shadow_factor = testShadowmap(world_position);
    }
    
    float metalness = occlusion_metallic_roughness.y;
    float roughness = occlusion_metallic_roughness.z;
    
    vec3 V = normalize(u_camera_position - world_position);
    vec3 H = normalize(V+L);
    
    float NoH = max(0.0, dot(N, H));
    float NoV = max(0.0,dot(N, V));
    float NoL = max(0.0,dot(N, L));
    float LoH = max(0.0,dot(L, H));
    
    
   //we compute the reflection in base to the color and the metalness
   vec3 f0 = mix( vec3(0.5), color.xyz, metalness );
   
   //metallic materials do not have diffuse
   vec3 diffuseColor = (1.0 - metalness) * color.xyz;
   
   //compute the specular
   vec3 Fr_d = specularBRDF(  roughness, f0, NoH, NoV, NoL, LoH);
   
   // Here we use the Burley, but you can replace it by the Lambert.
   // linearRoughness = squared roughness
   vec3 Fd_d = diffuseColor * Fd_Burley(NoV,NoL,LoH,roughness * roughness); 
   
   //add diffuse and specular reflection
   vec3 direct = Fr_d + Fd_d;
   
   //compute how much light received the pixel
   vec3 lightParams = pow(u_light_color, vec3(2.2)) * attenuation_factor * spot_factor * shadow_factor; 
   
   //modulate direct light by light received
   
   float ambient_occlusion_factor = texture(u_ssao_texture, uv).x;
   vec3 total_light = direct * lightParams + emissive.xyz;
    

    //total_light += NdotL * u_light_color * attenuation_factor * spot_factor * shadow_factor;
    //total_light += texture(u_emissive_texture, v_uv).xyz * u_emissive;

    
    color.xyz *= total_light;
    FragColor = color;
}

\ambient.fs

#version 330 core

in vec2 v_uv;

uniform sampler2D u_gb0_texture;
uniform sampler2D u_ssao_texture;

uniform vec2 u_iRes;
uniform vec3 u_ambient_light;

out vec4 FragColor;

void main()
{

    vec2 uv = gl_FragCoord.xy * u_iRes.xy;
    
    vec4 gb0_color = texture(u_gb0_texture, uv);
    vec4 color = vec4(gb0_color.xyz, 1.0);
    color = vec4(pow(color.xyz,vec3(2.2)),1.0);
    
    float ambient_occlusion_factor = texture(u_ssao_texture, uv).x;
    vec3 total_light = vec3(u_ambient_light) * ambient_occlusion_factor;
    
    color.xyz *= total_light;
    FragColor = color;
}

\ssao.fs

#version 330 core

in vec2 v_uv;

uniform float u_time;
uniform float u_alpha_cutoff;

uniform sampler2D u_gb1_texture;
uniform sampler2D u_depth_texture;

uniform mat4 u_viewprojection;
uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;
uniform vec3 u_points[64];

out vec4 FragColor;

mat3 cotangent_frame(vec3 N, vec3 p, vec2 uv)
{
	// get edge vectors of the pixel triangle
	vec3 dp1 = dFdx( p );
	vec3 dp2 = dFdy( p );
	vec2 duv1 = dFdx( uv );
	vec2 duv2 = dFdy( uv );
	
	// solve the linear system
	vec3 dp2perp = cross( dp2, N );
	vec3 dp1perp = cross( N, dp1 );
	vec3 T = dp2perp * duv1.x + dp1perp * duv2.x;
	vec3 B = dp2perp * duv1.y + dp1perp * duv2.y;
 
	// construct a scale-invariant frame 
	float invmax = inversesqrt( max( dot(T,T), dot(B,B) ) );
	return mat3( T * invmax, B * invmax, N );
}


void main()
{

    vec2 uv = gl_FragCoord.xy * u_iRes.xy;
	
	float depth = texture(u_depth_texture, uv).x;
	
	if(depth >= 1.0)
	{
        FragColor = vec4(1.0);
        return;
    }	
    
    
	vec4 gb1_color = texture(u_gb1_texture, uv);
	vec3 N = normalize(gb1_color.xyz * 2.0 - vec3(1.0));

	
	vec4 screen_pos = vec4(uv.x*2.0-1.0, uv.y*2.0-1.0, depth*2.0-1.0, 1.0);
    vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 world_position = proj_worldpos.xyz / proj_worldpos.w;
	
	
	//lets use 64 samples
    const int samples = 64;
    int num = samples; //num samples that passed the are outside
    
    //for every sample around the point
    for( int i = 0; i < samples; ++i )
    {
        //to create the matrix33 to convert from tangent to world
        mat3 rotmat = cotangent_frame( N, world_position, uv );
        
        //rotate a point is easy
        vec3 rotated_point = rotmat * u_points[i];

    	//compute is world position using the random
    	vec3 p = world_position + rotated_point * 10.0;
    	//find the uv in the depth buffer of this point
    	vec4 proj = u_viewprojection * vec4(p,1.0);
    	proj.xy /= proj.w; //convert to clipspace from homogeneous
    	//apply a tiny bias to its z before converting to clip-space
    	proj.z = (proj.z - 0.005) / proj.w;
    	proj.xyz = proj.xyz * 0.5 + vec3(0.5); //to [0..1]
    	//read p true depth
    	float pdepth = texture( u_depth_texture, proj.xy ).x;
    	//compare true depth with its depth
    	float difference = proj.z - pdepth;
    	if( difference > 0.0 && difference < 0.001) //if true depth smaller, is inside
    		num--; //remove this point from the list of visible
    }
    
    //finally, compute the AO factor as the ratio of visible points
    float ao = float(num) / float(samples);
    
    FragColor = vec4(ao);
}

\gamma.fs

#version 330 core

in vec2 v_uv;

uniform sampler2D u_texture;
uniform float u_scale;
uniform float u_average_lum;
uniform float u_lumwhite2;

out vec4 FragColor;

void main()
{
    
    vec4 color = texture2D( u_texture, v_uv );
    vec3 rgb = color.xyz;

    float lum = dot(rgb, vec3(0.2126, 0.7152, 0.0722));
    float L = (u_scale / u_average_lum) * lum;
    float Ld = (L * (1.0 + L / u_lumwhite2)) / (1.0 + L);

    rgb = (rgb / lum) * Ld;
    rgb = max(rgb,vec3(0.001));
    rgb = pow( rgb, vec3(1.0/2.2));
    FragColor = vec4( rgb, color.a );
}

\probe.fs

#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;
in vec4 v_color;

uniform vec3 u_coeffs[9];

out vec4 FragColor;

const float Pi = 3.141592654;
const float CosineA0 = Pi;
const float CosineA1 = (2.0 * Pi) / 3.0;
const float CosineA2 = Pi * 0.25;
struct SH9 { float c[9]; }; //to store weights
struct SH9Color { vec3 c[9]; }; //to store colors

void SHCosineLobe(in vec3 dir, out SH9 sh) //SH9
{
	// Band 0
	sh.c[0] = 0.282095 * CosineA0;
	// Band 1
	sh.c[1] = 0.488603 * dir.y * CosineA1; 
	sh.c[2] = 0.488603 * dir.z * CosineA1;
	sh.c[3] = 0.488603 * dir.x * CosineA1;
	// Band 2
	sh.c[4] = 1.092548 * dir.x * dir.y * CosineA2;
	sh.c[5] = 1.092548 * dir.y * dir.z * CosineA2;
	sh.c[6] = 0.315392 * (3.0 * dir.z * dir.z - 1.0) * CosineA2;
	sh.c[7] = 1.092548 * dir.x * dir.z * CosineA2;
	sh.c[8] = 0.546274 * (dir.x * dir.x - dir.y * dir.y) * CosineA2;
}

vec3 ComputeSHIrradiance(in vec3 normal, in SH9Color sh)
{
	// Compute the cosine lobe in SH, oriented about the normal direction
	SH9 shCosine;
	SHCosineLobe(normal, shCosine);
	// Compute the SH dot product to get irradiance
	vec3 irradiance = vec3(0.0);
	for(int i = 0; i < 9; ++i)
		irradiance += sh.c[i] * shCosine.c[i];

	return irradiance;
}


void main()
{

    SH9Color sh;
    for(int i = 0; i<9; i++){
    
        sh.c[i] = u_coeffs[i];
    
    }
    vec3 N = normalize(v_normal);
    vec3 irradiance = ComputeSHIrradiance(N, sh);
    
    FragColor = vec4(irradiance, 1.0);
}

\irradiance.fs

#version 330 core

in vec2 v_uv;

uniform float u_time;
uniform float u_alpha_cutoff;

uniform sampler2D u_gb0_texture;
uniform sampler2D u_gb1_texture;
uniform sampler2D u_depth_texture;
uniform sampler2D u_irradiance_texture;

uniform mat4 u_viewprojection;
uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;
uniform vec3 u_irradiance_start;
uniform vec3 u_irradiance_end;
uniform vec3 u_irradiance_dimension;
uniform float u_irr_normal_distance;
uniform float u_num_probes;
uniform vec3 u_irr_delta;

struct SH9Color { vec3 c[9]; }; //to store colors

out vec4 FragColor;

const float Pi = 3.141592654;
const float CosineA0 = Pi;
const float CosineA1 = (2.0 * Pi) / 3.0;
const float CosineA2 = Pi * 0.25;
struct SH9 { float c[9]; }; //to store weights
struct SH9Color { vec3 c[9]; }; //to store colors

void SHCosineLobe(in vec3 dir, out SH9 sh) //SH9
{
	// Band 0
	sh.c[0] = 0.282095 * CosineA0;
	// Band 1
	sh.c[1] = 0.488603 * dir.y * CosineA1; 
	sh.c[2] = 0.488603 * dir.z * CosineA1;
	sh.c[3] = 0.488603 * dir.x * CosineA1;
	// Band 2
	sh.c[4] = 1.092548 * dir.x * dir.y * CosineA2;
	sh.c[5] = 1.092548 * dir.y * dir.z * CosineA2;
	sh.c[6] = 0.315392 * (3.0 * dir.z * dir.z - 1.0) * CosineA2;
	sh.c[7] = 1.092548 * dir.x * dir.z * CosineA2;
	sh.c[8] = 0.546274 * (dir.x * dir.x - dir.y * dir.y) * CosineA2;
}

vec3 ComputeSHIrradiance(in vec3 normal, in SH9Color sh)
{
	// Compute the cosine lobe in SH, oriented about the normal direction
	SH9 shCosine;
	SHCosineLobe(normal, shCosine);
	// Compute the SH dot product to get irradiance
	vec3 irradiance = vec3(0.0);
	for(int i = 0; i < 9; ++i)
		irradiance += sh.c[i] * shCosine.c[i];

	return irradiance;
}


void main()
{

    vec2 uv = gl_FragCoord.xy * u_iRes.xy;
	
	float depth = texture(u_depth_texture, uv).x;
	
	if(depth >= 1.0)
	{
        FragColor = vec4(1.0);
        return;
    }	
    
    
	vec4 gb1_color = texture(u_gb1_texture, uv);
	vec3 N = normalize(gb1_color.xyz * 2.0 - vec3(1.0));

	
	vec4 screen_pos = vec4(uv.x*2.0-1.0, uv.y*2.0-1.0, depth*2.0-1.0, 1.0);
    vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 world_position = proj_worldpos.xyz / proj_worldpos.w;
	
	vec3 irr_range = u_irradiance_end - u_irradiance_start;
    vec3 irr_local_pos = clamp( world_position - u_irradiance_start + N * u_irr_normal_distance, vec3(0.0), irr_range );
    
    //convert from world pos to grid pos
    vec3 irr_norm_pos = irr_local_pos / u_irr_delta;
    
    //round values as we cannot fetch between rows for now
    vec3 local_indices = round( irr_norm_pos );
    
    //compute in which row is the probe stored
    float row = local_indices.x + local_indices.y * u_irradiance_dimension.x + local_indices.z * u_irradiance_dimension.x * u_irradiance_dimension.y;
    
    //find the UV.y coord of that row in the probes texture
    float row_uv = (row + 1.0) / (u_num_probes + 1.0);
    
    SH9Color sh;
    
    //fill the coefficients
    const float d_uvx = 1.0 / 9.0;
    for(int i = 0; i < 9; ++i)
    {
    	vec2 coeffs_uv = vec2( (float(i)+0.5) * d_uvx, row_uv );
    	sh.c[i] = texture( u_irradiance_texture, coeffs_uv).xyz;
    }
    
    //now we can use the coefficients to compute the irradiance
    vec3 irradiance = ComputeSHIrradiance( N, sh );

    vec3 color = pow(texture(u_gb0_texture, uv).xyz,vec3(2.2))* irradiance;
    FragColor = vec4(color, 1.0);
}

\skybox.fs

#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;

uniform samplerCube u_texture;
uniform vec3 u_camera_position;

out vec4 FragColor;

void main()
{
	vec3 V = v_world_position - u_camera_position;
	FragColor = texture( u_texture, V );
}

\reflection_probe.fs

#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;

uniform samplerCube u_texture;
uniform vec3 u_camera_position;

out vec4 FragColor;

void main()
{
	vec3 V = v_world_position - u_camera_position;
	vec3 N = normalize(v_normal);
	vec3 R = reflect(V, N);
	FragColor = textureLod( u_texture, R, 0 );
}

\volumetric.fs

#version 330 core

in vec2 v_uv;

uniform vec3 u_camera_position;

uniform sampler2D u_depth_texture;

uniform mat4 u_viewprojection;
uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;

uniform int u_light_type;
uniform vec3 u_light_color;
uniform vec3 u_light_position;
uniform float u_light_max_distance;
uniform vec3 u_light_direction;
uniform float u_light_cone_angle;
uniform float u_light_exp;

uniform int u_light_casts_shadows;
uniform sampler2D u_light_shadowmap;
uniform mat4 u_shadow_viewproj;
uniform float u_shadow_bias;

uniform float u_air_density;

out vec4 FragColor;

const int SAMPLES = 64;

float testShadowmap(vec3 pos)
{
    //project our 3D position to the shadowmap
    vec4 proj_pos = u_shadow_viewproj * vec4(pos,1.0);

    //from homogeneus space to clip space
    vec2 shadow_uv = proj_pos.xy / proj_pos.w;

    //from clip space to uv space
    shadow_uv = shadow_uv * 0.5 + vec2(0.5);

    //get point depth [-1 .. +1] in non-linear space
    float real_depth = (proj_pos.z - u_shadow_bias) / proj_pos.w;

    //normalize from [-1..+1] to [0..+1] still non-linear
    real_depth = real_depth * 0.5 + 0.5;

    //read depth from depth buffer in [0..+1] non-linear
    float shadow_depth = texture( u_light_shadowmap, shadow_uv).x;

    //compute final shadow factor by comparing
    float shadow_factor = 1.0;

    //we can compare them, even if they are not linear
    if( shadow_depth < real_depth )
        shadow_factor = 0.0;

    return shadow_factor;
}

void main()
{

    vec2 uv = gl_FragCoord.xy * u_iRes.xy;

	
	float depth = texture( u_depth_texture, uv ).x;
	vec4 screen_pos = vec4(uv.x*2.0-1.0, uv.y*2.0-1.0, depth*2.0-1.0, 1.0);
    vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 world_position = proj_worldpos.xyz / proj_worldpos.w;
	
    
    //compute ray info
    vec3 ray_start = u_camera_position;
    vec3 ray_dir = ( world_position - ray_start );
    float ray_length = length(ray_dir);
    ray_dir /= ray_length;
    ray_dir = normalize(ray_dir);
    ray_length = min( 500.0, ray_length ); //max ray
    
    float step_dist = ray_length / float(SAMPLES);
    
    vec3 current_pos = ray_start;
    vec3 ray_offset = ray_dir * step_dist;
    
    //how visible is the point at the end of the ray
    float transparency = 1.0;
    
    //how much transparency gets removed per world unit of the ray
    float air_density = u_air_density;

    vec3 irradiance = vec3(0.0);
    
    for(int i = 0; i < SAMPLES; ++i)
    {
    	//compute illumination in this point
        //...
        vec3 light = u_light_color * testShadowmap(current_pos);
    
        //accumulate the amount of light
        irradiance += light * transparency * (air_density * step_dist);

        //reduce visibility
        transparency -= air_density * step_dist;
    
        //too dense, nothing can be seen behind
        if( transparency < 0.001 )
            break;

    	//advance to next position
    	current_pos.xyz += ray_offset;
    }

    FragColor = vec4(irradiance, 1.0 - transparency);
}